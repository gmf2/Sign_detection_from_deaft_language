{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# REQUIRED IMPORTS FROM STANDARD PACKAGES\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "from glob import glob\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.externals.joblib import parallel_backend\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# IMPORTS FROM THE UTIL LIBRARY PROVIDED BY US\n",
    "\n",
    "import util.vis as V\n",
    "import util.helpers as H\n",
    "\n",
    "# Normally, all libraries are loaded only once, \n",
    "# even if you execute the import code multiple times\n",
    "# This code is helpful if you make your own helper libraries \n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "# list your libraries below with aimport: should ensure \n",
    "#they are reloaded each time without having to restart your kernel\n",
    "# in this case, our libraries are used as an example\n",
    "\n",
    "%aimport util.helpers, util.vis\n",
    "%aimport features_extraction\n",
    "%aimport augmentation\n",
    "%aimport Analysis\n",
    "%aimport validation\n",
    "%aimport preprocessing\n",
    "%aimport upsampling\n",
    "\n",
    "# seed random generator such that this notebook always returns the same values \n",
    "# (this is by no means necessary, but it is useful for reproducability of results)\n",
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "POSE_DIR = '../data/pose'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_sample(sample):\n",
    "    counter = 0\n",
    "    no_hands_present = False\n",
    "    for frame in sample:\n",
    "        if (frame[4][0] == 0 or frame[7][0] == 0):\n",
    "            counter += 1\n",
    "        if (frame[4][0] == 0 and frame[7][0] == 0):\n",
    "            no_hands_present = True\n",
    "    if counter/len(sample) > 0.5 or no_hands_present:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "##Loading all the training data\n",
    "dataset_file=pjoin(DATA_DIR,'labels.csv')\n",
    "\n",
    "train_samples=[]\n",
    "train_labels=[]\n",
    "train_persons = []\n",
    "train_personlabels = []\n",
    "\n",
    "with open(dataset_file) as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    sample_index = 0\n",
    "    preprocessing_outliers = [229, 297, 1316, 1780, 1817, 49, 495, 541, 746, 878, 2910]\n",
    "    outliers_jens_fixing_gap1 = [85 , 398 , 717 , 766 , 923 , 979 ,1111 ,1280 ,1671 ,1778 ,1960 ,1993 ,2038 ,2089, 2097, 2135 ,2140, 2145, 2417 ,2463 ,2554 ,2579, 2594, 2794, 2832 ,2975, 3138, 3211, 3215, 3325 ,3341 ,3396 ,3399 ,3482 ,3566, 3649, 3702]\n",
    "    outliers_jens_fixing_gap2 = [264,322,578,592,663,717,766,770,885,888,894,901,906,917,923,933,949,954,964,979,986,1117,1151,1152,1159,1161,1171,1199,1227,1257,1297,1573,1600,1607,1665,1671,1684,1701,1767,1778,1831,1859,1883,1930,1931,1932,1943,1960,1972,1993,1999,2037,2050,2056,2060,2089,2091,2097,2106,2119,2135,2140,2167,2191,2209,2231,2232,2235,2260,2268,2289,2334,2336,2538,2551,2554,2579,2602,2614,2637,2683,2688,2694,2699,2726,2741,2787,2803,2810,2841,2844,2845,2848,2887,2888,2893,2902,2943,2947,2954,2967,2975,2984,2990,3037,3064,3073,3078,3087,3103,3118,3119,3136,3138,3149,3170,3283,3293,3298,3305,3332,3342,3435,3475,3482,3561,3589,3590,3621,3629,3641,3649,3658,3672,3693,3697,3699,3702,3709,3710]\n",
    "    outliers_robbe_fixing_gap = [2538, 1753, 1327, 2954, 2956, 2958, 4, 1111, 1117, 1118, 2167, 1992, 1993, 1573, 1575, 1576, 977, 245, 1846, 1909, 2435, 2545, 2590, 2815, 3515, 396, 421, 434, 494, 676, 718, 795, 815, 821, 882, 977, 991, 1016, 1035, 1111, 1295, 1308, 1524, 1564, 1586, 1633, 1634, 1804]\n",
    "    #add [2538, 1753, 1327, 2954, 2956, 2958, 4, 1111, 1117, 1118]\n",
    "    for row in reader: \n",
    "        name, _gloss, label, _person = row\n",
    "        sample = np.load(pjoin(POSE_DIR, 'train', name+'.npy'))\n",
    "        #if (sample_index not in preprocessing_outliers) and (sample_index not in outliers_jens_fixing_gap1) and (sample_index not in outliers_jens_fixing_gap2) and (sample_index not in outliers_robbe_fixing_gap):            \n",
    "        if keep_sample(sample):\n",
    "            train_samples.append(sample)\n",
    "            train_labels.append(int(label))\n",
    "            train_persons.append(_person)\n",
    "            train_personlabels.append((label, _person))\n",
    "        sample_index += 1\n",
    "\n",
    "train_samples=np.array(train_samples)\n",
    "train_labels=np.array(train_labels)\n",
    "\n",
    "##Loading all the test data\n",
    "all_test_files = sorted(glob(pjoin(POSE_DIR, 'test', '*.npy')))  \n",
    "\n",
    "test_samples = []\n",
    "for numpy_file in all_test_files:\n",
    "    sample = np.load(numpy_file)\n",
    "    test_samples.append(sample)\n",
    "    \n",
    "test_samples = np.array(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "3560\n"
     ]
    }
   ],
   "source": [
    "#Code to determine the outliers\n",
    "temp = []\n",
    "for i in range(len(train_samples)):\n",
    "    teller = 0\n",
    "    for frame in train_samples[i]:\n",
    "        if (frame[4][0] == 0 or frame[7][0] == 0) and not(frame[4][0] == 0 and frame[7][0] == 0):\n",
    "            teller += 1\n",
    "    if teller/len(train_samples[i]) > 0.5:\n",
    "        temp.append(i)\n",
    "temp=np.unique(temp)\n",
    "print((temp))\n",
    "print(len(train_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_samples, upsampled_labels, upsampled_label_list, upsampled_persons = upsampling.upsample(train_samples, train_labels, train_persons, train_personlabels)\n",
    "print(len(upsampled_samples), len(upsampled_labels), upsampled_label_list, len(upsampled_persons))\n",
    "train_samples = np.array(upsampled_samples)\n",
    "train_labels = np.array(upsampled_labels)\n",
    "train_persons = np.array(upsampled_persons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_samples = augmentation.augment_data(train_samples)\n",
    "#train_labels = np.concatenate(( train_labels,train_labels, train_labels))\n",
    "#train_persons = np.concatenate(( train_persons,train_persons, train_persons))\n",
    "#train_personlabels = np.concatenate(( train_personlabels,train_personlabels, train_personlabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Centering finished ---\n",
      "--- Centering finished ---\n"
     ]
    }
   ],
   "source": [
    "#train_samples = preprocessing.rotate(train_samples)\n",
    "#train_samples = preprocessing.scale(train_samples)\n",
    "train_samples = preprocessing.centering(train_samples)\n",
    "\n",
    "#test_samples = preprocessing.rotate(test_samples)\n",
    "#test_samples = preprocessing.scale(test_samples)\n",
    "test_samples = preprocessing.centering(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features\n",
    "Here we use the features from the example notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3250: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\main\\Documents\\ML_competition\\features_extraction.py:1243: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vector_hand_fingers = vector_hand_fingers / np.linalg.norm(vector_hand_fingers)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features :  869\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(train_labels)\n",
    "X_train = features_extraction.extract_features(train_samples).values\n",
    "X_test = features_extraction.extract_features(test_samples).values\n",
    "num_features = X_train.shape[1]\n",
    "print(\"Number of features : \", num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions\n",
    "Custom scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Custom scoring functions\n",
    "\n",
    "def top3_acc_score(y_true, proba):\n",
    "    return H.mapk(proba,y_true)\n",
    "\n",
    "def map3_score(y_true, proba):\n",
    "    return H.top3_accuracy(proba, y_true)\n",
    "    \n",
    "\n",
    "acc = make_scorer(accuracy_score)\n",
    "top3_acc = make_scorer(top3_acc_score, needs_proba=True) \n",
    "map3 = make_scorer(map3_score, needs_proba=True)\n",
    "scoring_functions = {\"acc\": acc, \"top3_acc\": top3_acc, \"map3\": map3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed:  94\n"
     ]
    }
   ],
   "source": [
    "##Train validate data splitter for Cross Validation\n",
    "seed = np.random.randint(1,999)\n",
    "print(\"seed: \", seed)\n",
    "sgkf = validation.stratified_group_k_fold(train_samples, train_labels, train_persons, 5, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline & model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# the function below generates our rescaled pipeline model\n",
    "# with optimized hyperparameters (e.g.: regularisation parameter)\n",
    "def tune_svm_rbf(x_data,r_data,verbose=0):\n",
    "    pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        #('pca', PCA(n_components=400)),\n",
    "        ('selectfrommodel',SelectFromModel(ExtraTreesClassifier(n_estimators=100))),\n",
    "        #('selectkbest', SelectKBest(chi2)),\n",
    "        ('minmaxscaler', MinMaxScaler(feature_range=(0,1))),\n",
    "        ('svm', svm.SVC(kernel='rbf', probability = True))\n",
    "    ])\n",
    "\n",
    "    # Set the parameters by cross-validation\n",
    "    tuned_parameters = {'svm__C': np.logspace(4, 7, 3) ,'svm__gamma': np.logspace(-8, -5, 3)}\n",
    "\n",
    "    print(\"------ Start tuning hyperparameters ------\")\n",
    "    CV = GridSearchCV(pipe, tuned_parameters, n_jobs=-1, scoring=map3, pre_dispatch='n_jobs', cv=sgkf, verbose=2)\n",
    "    with parallel_backend('threading'):\n",
    "        CV.fit(x_data, r_data)\n",
    "    results = CV.cv_results_\n",
    "    params = CV.best_params_\n",
    "    print(\"------ Tuning hyperparameters finished ------\")\n",
    "    \n",
    "    bestC = params['svm__C']\n",
    "    bestGamma = params['svm__gamma']\n",
    "    \n",
    "    #bestN = CV.best_params_['selectfrommodel__n_estimators']\n",
    "    print(\"Optimal regularisation value: \", bestC)\n",
    "    print(\"Optimal gamma value: \", bestGamma)\n",
    "    #print(\"Optimal k value: \", bestN)\n",
    "    \n",
    "    optimal_pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        #('pca', PCA(n_components=400)),\n",
    "        ('selectfrommodel',SelectFromModel(ExtraTreesClassifier(n_estimators=100))),\n",
    "       # ('selectkbest', SelectKBest(chi2, k=bestK)),\n",
    "        ('minmaxscaler', MinMaxScaler(feature_range=(0,1))),\n",
    "        ('svm', svm.SVC(kernel='rbf', probability = True, C=bestC, gamma=bestGamma))\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    if verbose>0:\n",
    "    \n",
    "        print(\"Grid scores on training data set:\")\n",
    "        print()\n",
    "        cv_means = results['mean_test_score']\n",
    "        print(cv_means)\n",
    "        cv_stds = results['std_test_score']\n",
    "        for mean, std, params in zip(cv_means, cv_stds, results['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "\n",
    "    return optimal_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Start tuning hyperparameters ------\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10000.0, svm__gamma=1e-08 ................................[CV] svm__C=10000.0, svm__gamma=1e-08 ................................\n",
      "\n",
      "[CV] svm__C=10000.0, svm__gamma=1e-08 ................................\n",
      "[CV] svm__C=10000.0, svm__gamma=1e-08 ................................[CV] svm__C=10000.0, svm__gamma=1e-08 ................................\n",
      "[CV] svm__C=10000.0, svm__gamma=3.162277660168379e-07 ................\n",
      "\n",
      "[CV] svm__C=10000.0, svm__gamma=3.162277660168379e-07 ................[CV] svm__C=10000.0, svm__gamma=3.162277660168379e-07 ................\n",
      "\n",
      "[CV] ................. svm__C=10000.0, svm__gamma=1e-08, total=  35.1s\n",
      "[CV] svm__C=10000.0, svm__gamma=3.162277660168379e-07 ................\n",
      "[CV] . svm__C=10000.0, svm__gamma=3.162277660168379e-07, total=  35.2s\n",
      "[CV] svm__C=10000.0, svm__gamma=3.162277660168379e-07 ................\n",
      "[CV] ................. svm__C=10000.0, svm__gamma=1e-08, total=  36.7s\n",
      "[CV] svm__C=10000.0, svm__gamma=1e-05 ................................\n",
      "[CV] ................. svm__C=10000.0, svm__gamma=1e-08, total=  36.8s\n",
      "[CV] svm__C=10000.0, svm__gamma=1e-05 ................................\n",
      "[CV] . svm__C=10000.0, svm__gamma=3.162277660168379e-07, total=  38.5s\n",
      "[CV] svm__C=10000.0, svm__gamma=1e-05 ................................\n",
      "[CV] . svm__C=10000.0, svm__gamma=3.162277660168379e-07, total=  39.5s\n",
      "[CV] svm__C=10000.0, svm__gamma=1e-05 ................................\n",
      "[CV] ................. svm__C=10000.0, svm__gamma=1e-08, total=  40.2s\n",
      "[CV] svm__C=10000.0, svm__gamma=1e-05 ................................\n",
      "[CV] ................. svm__C=10000.0, svm__gamma=1e-08, total=  40.6s\n",
      "[CV] svm__C=316227.7660168379, svm__gamma=1e-08 ......................\n",
      "[CV] ................. svm__C=10000.0, svm__gamma=1e-05, total=  19.9s\n",
      "[CV] svm__C=316227.7660168379, svm__gamma=1e-08 ......................\n",
      "[CV] ................. svm__C=10000.0, svm__gamma=1e-05, total=  20.4s\n",
      "[CV] svm__C=316227.7660168379, svm__gamma=1e-08 ......................\n",
      "[CV] ................. svm__C=10000.0, svm__gamma=1e-05, total=  21.7s\n",
      "[CV] svm__C=316227.7660168379, svm__gamma=1e-08 ......................\n",
      "[CV] ................. svm__C=10000.0, svm__gamma=1e-05, total=  22.9s\n",
      "[CV] svm__C=316227.7660168379, svm__gamma=1e-08 ......................\n",
      "[CV] ................. svm__C=10000.0, svm__gamma=1e-05, total=  22.6s\n",
      "[CV] svm__C=316227.7660168379, svm__gamma=3.162277660168379e-07 ......\n",
      "[CV] . svm__C=10000.0, svm__gamma=3.162277660168379e-07, total=  33.1s\n",
      "[CV] svm__C=316227.7660168379, svm__gamma=3.162277660168379e-07 ......\n",
      "[CV] . svm__C=10000.0, svm__gamma=3.162277660168379e-07, total=  35.2s\n",
      "[CV] svm__C=316227.7660168379, svm__gamma=3.162277660168379e-07 ......\n",
      "[CV] ....... svm__C=316227.7660168379, svm__gamma=1e-08, total=  38.3s\n",
      "[CV] svm__C=316227.7660168379, svm__gamma=3.162277660168379e-07 ......\n",
      "[CV]  svm__C=316227.7660168379, svm__gamma=3.162277660168379e-07, total=  19.4s\n",
      "[CV] svm__C=316227.7660168379, svm__gamma=3.162277660168379e-07 ......\n",
      "[CV]  svm__C=316227.7660168379, svm__gamma=3.162277660168379e-07, total=  23.8s\n",
      "[CV] svm__C=316227.7660168379, svm__gamma=1e-05 ......................\n",
      "[CV]  svm__C=316227.7660168379, svm__gamma=3.162277660168379e-07, total=  19.8s\n",
      "[CV] svm__C=316227.7660168379, svm__gamma=1e-05 ......................\n",
      "[CV] ....... svm__C=316227.7660168379, svm__gamma=1e-08, total=  35.3s\n",
      "[CV] svm__C=316227.7660168379, svm__gamma=1e-05 ......................\n",
      "[CV] ....... svm__C=316227.7660168379, svm__gamma=1e-08, total=  35.9s\n",
      "[CV] svm__C=316227.7660168379, svm__gamma=1e-05 ......................\n",
      "[CV] ....... svm__C=316227.7660168379, svm__gamma=1e-08, total=  40.7s\n",
      "[CV] svm__C=316227.7660168379, svm__gamma=1e-05 ......................\n",
      "[CV]  svm__C=316227.7660168379, svm__gamma=3.162277660168379e-07, total=  23.6s\n",
      "[CV] svm__C=10000000.0, svm__gamma=1e-08 .............................\n",
      "[CV] ....... svm__C=316227.7660168379, svm__gamma=1e-08, total=  41.8s\n",
      "[CV] svm__C=10000000.0, svm__gamma=1e-08 .............................\n",
      "[CV]  svm__C=316227.7660168379, svm__gamma=3.162277660168379e-07, total=  22.6s\n",
      "[CV] svm__C=10000000.0, svm__gamma=1e-08 .............................\n",
      "[CV] ....... svm__C=316227.7660168379, svm__gamma=1e-05, total=  18.8s\n",
      "[CV] svm__C=10000000.0, svm__gamma=1e-08 .............................\n",
      "[CV] ....... svm__C=316227.7660168379, svm__gamma=1e-05, total=  23.4s\n",
      "[CV] svm__C=10000000.0, svm__gamma=1e-08 .............................\n",
      "[CV] ....... svm__C=316227.7660168379, svm__gamma=1e-05, total=  19.7s\n",
      "[CV] svm__C=10000000.0, svm__gamma=3.162277660168379e-07 .............\n",
      "[CV] ....... svm__C=316227.7660168379, svm__gamma=1e-05, total=  19.4s\n",
      "[CV] svm__C=10000000.0, svm__gamma=3.162277660168379e-07 .............\n",
      "[CV] .............. svm__C=10000000.0, svm__gamma=1e-08, total=  20.7s\n",
      "[CV] svm__C=10000000.0, svm__gamma=3.162277660168379e-07 .............\n",
      "[CV] ....... svm__C=316227.7660168379, svm__gamma=1e-05, total=  21.4s\n",
      "[CV] svm__C=10000000.0, svm__gamma=3.162277660168379e-07 .............\n",
      "[CV] .............. svm__C=10000000.0, svm__gamma=1e-08, total=  20.0s\n",
      "[CV] svm__C=10000000.0, svm__gamma=3.162277660168379e-07 .............\n",
      "[CV] .............. svm__C=10000000.0, svm__gamma=1e-08, total=  18.5s\n",
      "[CV] svm__C=10000000.0, svm__gamma=1e-05 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. svm__C=10000000.0, svm__gamma=1e-08, total=  19.8s\n",
      "[CV] svm__C=10000000.0, svm__gamma=1e-05 .............................\n",
      "[CV] .............. svm__C=10000000.0, svm__gamma=1e-08, total=  19.4s\n",
      "[CV] svm__C=10000000.0, svm__gamma=1e-05 .............................\n",
      "[CV]  svm__C=10000000.0, svm__gamma=3.162277660168379e-07, total=  18.0s\n",
      "[CV] svm__C=10000000.0, svm__gamma=1e-05 .............................\n",
      "[CV]  svm__C=10000000.0, svm__gamma=3.162277660168379e-07, total=  20.0s\n",
      "[CV] svm__C=10000000.0, svm__gamma=1e-05 .............................\n"
     ]
    }
   ],
   "source": [
    "sgkf = validation.stratified_group_k_fold(train_samples, train_labels, train_persons, 5, seed)\n",
    "\n",
    "optimal_pipe = tune_svm_rbf(X_train, y_train, 1)\n",
    "\n",
    "##Train validate data splitter for Cross Validation\n",
    "sgkf = validation.stratified_group_k_fold(train_samples, train_labels, train_persons, 5, seed)\n",
    "\n",
    "with parallel_backend('threading'):\n",
    "    scores = cross_val_score(optimal_pipe, X_train, y_train, scoring=map3, cv=sgkf, n_jobs=-1, pre_dispatch='n_jobs')\n",
    "print(scores)\n",
    "print(\"Average (cross validated) map@3 score: \",scores.mean(),\", stdev: \",scores.std())\n",
    "\n",
    "optimal_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate kaggle submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probas = optimal_pipe.predict_proba(X_test)\n",
    "H.create_submission(test_probas, 'submission_svc_slectfrommoel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis\n",
    "Generate confusion matrix on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgkf = validation.stratified_group_k_fold(train_samples, train_labels, train_persons, 5)\n",
    "with parallel_backend('threading'):\n",
    "    y_pred = cross_val_predict(optimal_pipe, X_train, y_train, cv=sgkf, n_jobs=-1, pre_dispatch='n_jobs')\n",
    "Analysis.plot_confusion_matrix(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the precision, recall, F1 score, TP, FP and NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ANALYSIS\n",
    "\n",
    "#PLOTS\n",
    "P,R,F1 = None,None,None # compute these for class c on the TEST SET\n",
    "\n",
    "#ORDER PROBABILITIES\n",
    "prob_order = H.get_ordered_predictions(train_probas)\n",
    "# Get the top prediction per sample.\n",
    "top_prob = prob_order[:,:1]\n",
    "top_prob_2= prob_order[:,1:2]\n",
    "top_prob_3= prob_order[:,2:3]\n",
    "\n",
    "#PRECISION,RECALL,F1 PER CLASS\n",
    "print(\"--- TEST SET ---\")\n",
    "macro_f1 = 0 \n",
    "for c in range(0,18):\n",
    "    print(\"Class :{}\".format(c))\n",
    "    print('------')\n",
    "    for k in range(1,4):\n",
    "        print(\"k :{}\".format(k))\n",
    "        P,R,F1 = None,None,None # compute these for class c on the TEST SET\n",
    "        # YOUR CODE HERE\n",
    "        P,R,F1,TP,FP,FN = Analysis.compute_precision_recall_F1_label(train_probas, y_train, k,c)\n",
    "        #raise NotImplementedError()\n",
    "        if F1!=0.0:\n",
    "            macro_f1 += F1\n",
    "        \n",
    "        print(\"Number of TP,FP,FN:\")\n",
    "        print('TP in k{} for class {}:{}'.format(k,c,TP))\n",
    "        print('FP in k{} for class {}:{}'.format(k,c,FP))\n",
    "        print('FN in k{} for class {}:{}'.format(k,c,FN))\n",
    "        print(\"------\")\n",
    "        print('Precision K:{} for class {}: {}'.format(k,c,P))\n",
    "        print('Recall K:{} for class    {}: {}'.format(k,c,R))\n",
    "        print('F1 K:{} for class        {}: {}'.format(k,c,F1))\n",
    "        \n",
    "    print('-----------------------------')\n",
    "        \n",
    "        \n",
    "macro_f1 /= 3        \n",
    "\n",
    "print(f'F1: {macro_f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
