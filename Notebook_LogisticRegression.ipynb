{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning competition\n",
    "#### Logistic Regression Notebook\n",
    "##### Loading all the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Environment Ready\n"
     ]
    }
   ],
   "source": [
    "# REQUIRED IMPORTS FROM STANDARD PACKAGES\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import random\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from os.path import join as pjoin\n",
    "from glob import glob\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.externals.joblib import parallel_backend\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "# IMPORTS FROM THE UTIL LIBRARY PROVIDED BY US\n",
    "\n",
    "import util.vis as V\n",
    "import util.helpers as H\n",
    "\n",
    "# Normally, all libraries are loaded only once, \n",
    "# even if you execute the import code multiple times\n",
    "# This code is helpful if you make your own helper libraries \n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "# list your libraries below with aimport: should ensure \n",
    "#they are reloaded each time without having to restart your kernel\n",
    "# in this case, our libraries are used as an example\n",
    "\n",
    "%aimport util.helpers, util.vis\n",
    "%aimport features_extraction\n",
    "%aimport augmentation\n",
    "%aimport validation\n",
    "%aimport preprocessing\n",
    "%aimport upsampling\n",
    "\n",
    "# seed random generator such that this notebook always returns the same values \n",
    "# (this is by no means necessary, but it is useful for reproducability of results)\n",
    "rng = np.random.RandomState(42)\n",
    "print(\"Environment Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Ready\n"
     ]
    }
   ],
   "source": [
    "# PATHS\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "POSE_DIR = '../data/pose'\n",
    "\n",
    "##Loading all the training data\n",
    "dataset_file=pjoin(DATA_DIR,'labels.csv')\n",
    "\n",
    "train_samples=[]\n",
    "train_labels=[]\n",
    "train_persons = []\n",
    "train_personlabels = []\n",
    "\n",
    "with open(dataset_file) as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    sample_index = 0\n",
    "    for row in reader: \n",
    "        name, _gloss, label, _person = row\n",
    "        sample = np.load(pjoin(POSE_DIR, 'train', name+'.npy'))\n",
    "        if upsampling.keep_sample(sample):\n",
    "            train_samples.append(sample)\n",
    "            train_labels.append(int(label))\n",
    "            train_persons.append(_person)\n",
    "            train_personlabels.append((label, _person))\n",
    "        sample_index += 1\n",
    "\n",
    "##Loading all the test data\n",
    "all_test_files = sorted(glob(pjoin(POSE_DIR, 'test', '*.npy')))  \n",
    "\n",
    "test_samples = []\n",
    "for numpy_file in all_test_files:\n",
    "    sample = np.load(numpy_file)\n",
    "    test_samples.append(sample)\n",
    "test_samples = np.array(test_samples)\n",
    "\n",
    "print(\"Data Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Centering finished ---\n",
      "--- Centering finished ---\n"
     ]
    }
   ],
   "source": [
    "train_samples = preprocessing.centering(train_samples)\n",
    "test_samples = preprocessing.centering(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3250: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\main\\Documents\\ML_competition\\features_extraction.py:1243: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vector_hand_fingers = vector_hand_fingers / np.linalg.norm(vector_hand_fingers)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  869\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(train_labels)\n",
    "X_train = features_extraction.extract_features(train_samples).values\n",
    "X_test = features_extraction.extract_features(test_samples).values\n",
    "num_features = X_train.shape[1]\n",
    "print(\"Number of features: \", num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Custom scoring functions\n",
    "\n",
    "def map3_score(y_true, proba):\n",
    "    return H.top3_accuracy(proba, y_true)\n",
    "    \n",
    "map3 = make_scorer(map3_score, needs_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  28\n"
     ]
    }
   ],
   "source": [
    "##Train validate data splitter for Cross Validation\n",
    "seed = np.random.randint(1,999)\n",
    "print(\"Seed: \", seed)\n",
    "sgkf = validation.stratified_group_k_fold(train_samples, train_labels, train_persons, 5, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pipeline model & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function below generates our rescaled pipeline model\n",
    "# with optimized hyperparameters (e.g.: regularisation parameter)\n",
    "def tune_pipeline(x_data,r_data,verbose=0):\n",
    "    pipe = Pipeline([\n",
    "        ('scale', RobustScaler()),\n",
    "        ('selectkbest', SelectKBest(f_classif)), \n",
    "        ('logreg', LogisticRegression(multi_class='multinomial', class_weight='balanced'))\n",
    "    ])\n",
    "\n",
    "    # Set the parameters by cross-validation\n",
    "    tuned_parameters = {'logreg__C': np.logspace(-1, 0, 2),\n",
    "                        'logreg__solver': ['sag'], \n",
    "                        'selectkbest__k': np.arange(220, 230, 5)}\n",
    "\n",
    "    print(\"------ Start tuning hyperparameters ------\")\n",
    "    CV = GridSearchCV(pipe, tuned_parameters, n_jobs=-1, scoring=map3, pre_dispatch='n_jobs', cv=sgkf, verbose=2, return_train_score=True)\n",
    "    with parallel_backend('threading'):\n",
    "        CV.fit(x_data, r_data)\n",
    "    print(\"------ Tuning hyperparameters finished ------\")\n",
    "    \n",
    "    bestC = CV.best_params_['logreg__C']\n",
    "    bestSolver = CV.best_params_['logreg__solver']\n",
    "    bestK = CV.best_params_['selectkbest__k']\n",
    "    print(\"Optimal regularisation value: \", bestC)\n",
    "    print(\"Optimal solver: \", bestSolver)\n",
    "    print(\"Optimal k value: \", bestK)\n",
    "    \n",
    "    optimal_pipe = Pipeline([\n",
    "        ('scale', RobustScaler()),\n",
    "        ('selectkbest', SelectKBest(f_classif, k=bestK)),\n",
    "        ('logreg', LogisticRegression(C=bestC, multi_class='multinomial', solver=bestSolver, class_weight='balanced'))\n",
    "        ])\n",
    "    \n",
    "    if verbose>0:\n",
    "        print(\"Grid validation scores on training data set:\")\n",
    "        cv_means = CV.cv_results_['mean_test_score']\n",
    "        print(cv_means)\n",
    "        cv_stds = CV.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(cv_means, cv_stds, CV.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "\n",
    "    return optimal_pipe, CV.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Start tuning hyperparameters ------\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] logreg__C=0.1, logreg__solver=sag, selectkbest__k=220 ...........\n",
      "[CV] logreg__C=0.1, logreg__solver=sag, selectkbest__k=220 ...........\n",
      "[CV] logreg__C=0.1, logreg__solver=sag, selectkbest__k=220 ...........\n",
      "[CV] logreg__C=0.1, logreg__solver=sag, selectkbest__k=220 ...........[CV] logreg__C=0.1, logreg__solver=sag, selectkbest__k=220 ...........\n",
      "\n",
      "[CV] logreg__C=0.1, logreg__solver=sag, selectkbest__k=225 ...........[CV] logreg__C=0.1, logreg__solver=sag, selectkbest__k=225 ...........[CV] logreg__C=0.1, logreg__solver=sag, selectkbest__k=225 ...........\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=0.1, logreg__solver=sag, selectkbest__k=220, total=  21.1s\n",
      "[CV] logreg__C=0.1, logreg__solver=sag, selectkbest__k=225 ...........\n",
      "[CV]  logreg__C=0.1, logreg__solver=sag, selectkbest__k=220, total=  21.1s\n",
      "[CV] logreg__C=0.1, logreg__solver=sag, selectkbest__k=225 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=0.1, logreg__solver=sag, selectkbest__k=220, total=  21.4s\n",
      "[CV] logreg__C=1.0, logreg__solver=sag, selectkbest__k=220 ...........\n",
      "[CV]  logreg__C=0.1, logreg__solver=sag, selectkbest__k=220, total=  21.6s\n",
      "[CV] logreg__C=1.0, logreg__solver=sag, selectkbest__k=220 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=0.1, logreg__solver=sag, selectkbest__k=225, total=  22.3s\n",
      "[CV] logreg__C=1.0, logreg__solver=sag, selectkbest__k=220 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=0.1, logreg__solver=sag, selectkbest__k=225, total=  24.2s\n",
      "[CV] logreg__C=1.0, logreg__solver=sag, selectkbest__k=220 ...........\n",
      "[CV]  logreg__C=0.1, logreg__solver=sag, selectkbest__k=220, total=  24.2s\n",
      "[CV] logreg__C=1.0, logreg__solver=sag, selectkbest__k=220 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=0.1, logreg__solver=sag, selectkbest__k=225, total=  27.3s\n",
      "[CV] logreg__C=1.0, logreg__solver=sag, selectkbest__k=225 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=1.0, logreg__solver=sag, selectkbest__k=220, total=  19.2s\n",
      "[CV] logreg__C=1.0, logreg__solver=sag, selectkbest__k=225 ...........\n",
      "[CV]  logreg__C=1.0, logreg__solver=sag, selectkbest__k=220, total=  18.4s\n",
      "[CV] logreg__C=1.0, logreg__solver=sag, selectkbest__k=225 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=1.0, logreg__solver=sag, selectkbest__k=220, total=  19.6s\n",
      "[CV] logreg__C=1.0, logreg__solver=sag, selectkbest__k=225 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=1.0, logreg__solver=sag, selectkbest__k=220, total=  17.1s\n",
      "[CV] logreg__C=1.0, logreg__solver=sag, selectkbest__k=225 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=0.1, logreg__solver=sag, selectkbest__k=225, total=  20.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=1.0, logreg__solver=sag, selectkbest__k=220, total=  20.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=0.1, logreg__solver=sag, selectkbest__k=225, total=  24.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=1.0, logreg__solver=sag, selectkbest__k=225, total=  18.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=1.0, logreg__solver=sag, selectkbest__k=225, total=  14.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=1.0, logreg__solver=sag, selectkbest__k=225, total=  15.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=1.0, logreg__solver=sag, selectkbest__k=225, total=  15.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   57.1s finished\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logreg__C=1.0, logreg__solver=sag, selectkbest__k=225, total=  15.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Tuning hyperparameters finished ------\n",
      "Optimal regularisation value:  0.1\n",
      "Optimal solver:  sag\n",
      "Optimal k value:  225\n",
      "Grid validation scores on training data set:\n",
      "[0.79016854 0.79269663 0.78876404 0.79185393]\n",
      "0.790 (+/-0.033) for {'logreg__C': 0.1, 'logreg__solver': 'sag', 'selectkbest__k': 220}\n",
      "0.793 (+/-0.035) for {'logreg__C': 0.1, 'logreg__solver': 'sag', 'selectkbest__k': 225}\n",
      "0.789 (+/-0.037) for {'logreg__C': 1.0, 'logreg__solver': 'sag', 'selectkbest__k': 220}\n",
      "0.792 (+/-0.039) for {'logreg__C': 1.0, 'logreg__solver': 'sag', 'selectkbest__k': 225}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77382646 0.78393352 0.81420765 0.81163435 0.77973568]\n",
      "Average (cross validated) map@3 score:  0.7926675316331205 , stdev:  0.016865459586132298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scale', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)), ('selectkbest', SelectKBest(k=225, score_func=<function f_classif at 0x000002A1CE37BEA0>)), ('logreg', LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "          fit_i...l2',\n",
       "          random_state=None, solver='sag', tol=0.0001, verbose=0,\n",
       "          warm_start=False))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgkf = validation.stratified_group_k_fold(train_samples, train_labels, train_persons, 5, seed)\n",
    "optimal_pipe, res = tune_pipeline(X_train, y_train, 1)\n",
    "\n",
    "##Train validate data splitter for Cross Validation\n",
    "sgkf = validation.stratified_group_k_fold(train_samples, train_labels, train_persons, 5, seed)\n",
    "\n",
    "with parallel_backend('threading'):\n",
    "    scores = cross_val_score(optimal_pipe, X_train, y_train, scoring=map3, cv=sgkf, n_jobs=-1, pre_dispatch='n_jobs')\n",
    "print(scores)\n",
    "print(\"Average (cross validated) map@3 score: \",scores.mean(),\", stdev: \",scores.std())\n",
    "\n",
    "optimal_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kaggle submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probas = optimal_pipe.predict_proba(X_test)\n",
    "H.create_submission(test_probas, 'LogisticRegressionTuned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
